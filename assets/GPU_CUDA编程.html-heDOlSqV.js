import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as a,o as r,b as t}from"./app-1sB8-tQp.js";const n="/assets/image-20250312130906933-CoH9rHl8.png",i="/assets/image-20250312130720176-DPTynQaG.png",l="/assets/image-20250312130826179-hlAM2_NA.png",o={},c=t('<h1 id="gpu-cuda-编程" tabindex="-1"><a class="header-anchor" href="#gpu-cuda-编程"><span>GPU，CUDA 编程</span></a></h1><blockquote><p>以下内容来自个人理解 + 大语言模型 回答</p></blockquote><h2 id="cuda-版本选择" tabindex="-1"><a class="header-anchor" href="#cuda-版本选择"><span>CUDA 版本选择</span></a></h2><p>CUDA 版本选择注意要搭配对应的 NVIDIA 驱动版本：</p><p><a href="https://blog.csdn.net/Strive_For_Future/article/details/104388165" target="_blank" rel="noopener noreferrer">win10 查看GPU型号，驱动版本，CUDA版本_怎么查看gpu版本号-CSDN博客</a></p><p><a href="https://blog.csdn.net/mouse1598189/article/details/86695400" target="_blank" rel="noopener noreferrer">不同版本cuda对应的NVIDIA驱动版本_cuda12.1对应的驱动版本-CSDN博客</a></p><h2 id="cpu-与-gpu" tabindex="-1"><a class="header-anchor" href="#cpu-与-gpu"><span>CPU 与 GPU</span></a></h2><figure><img src="'+n+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure><p>图片来源:<a href="https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf" target="_blank" rel="noopener noreferrer">https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf</a></p><h2 id="cuda" tabindex="-1"><a class="header-anchor" href="#cuda"><span>CUDA</span></a></h2><ul><li><p>采用 CUDA 编程模型 可以将程序中适合于并行计算部分的<strong>迁移至 GPU 执行</strong>；</p><ul><li><p>将<code>for</code>循环的迭代过程分摊到<code>GPU</code>的线程上，每个线程独立负责部分迭代过程，共同完成整个<code>for</code>循环的迭代；</p></li><li><p>需要考虑原先程序中 循环变量<code>i、j</code>与线程索引的映射关系；</p></li></ul></li><li><p>针对程序中 GPU 计算资源利用不充分问题，</p><ul><li><p>优化 <strong>数据存储布局</strong>（数组中数据的存放方式可能影响计算效率，为了更好利用 合并访问 减少 GPU 访问全局内存的次数（全局内存时延较大），将 AOS 改成了 SOA）；</p></li><li><p>AOS（Array of Structures）</p></li><li><p>SOA（Structure of Arrays）</p></li><li><p>AOS和SOA理解：结构体的所有属性放在一起 和 所有结构体的第n个属性放在一起；</p></li></ul></li><li><p>使用 <strong>共享内存</strong>（使用 线程块的共享内存作为全局内存的缓存）；</p><figure><img src="'+i+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><p>图片来源:<a href="https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf" target="_blank" rel="noopener noreferrer">https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf</a></p><ul><li><p><strong>线程层次结构</strong>（如何组织 GPU 中的线程，NVIDIA GPU 的 SM 每次调度 32 个线程，若线程块大小非 32 倍数或资源分配不当，可能造成部分线程未被利用）。</p><figure><img src="'+l+'" alt="" tabindex="0" loading="lazy"><figcaption></figcaption></figure></li></ul><p>图片来源:<a href="https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf" target="_blank" rel="noopener noreferrer">https://www.nvidia.cn/docs/IO/51635/NVIDIA_CUDA_Programming_Guide_1.1_chs.pdf</a></p><h2 id="概念理解" tabindex="-1"><a class="header-anchor" href="#概念理解"><span>概念理解</span></a></h2><h3 id="sm-streaming-multiprocessor" tabindex="-1"><a class="header-anchor" href="#sm-streaming-multiprocessor"><span>SM（Streaming Multiprocessor）</span></a></h3><p>SM 是 NVIDIA GPU 的核心计算单元，负责执行 CUDA 线程；每个 SM 包含多个 CUDA 核心，并配备寄存器、共享内存、缓存等资源。</p><p>并行执行多个线程块（Block），每个线程块包含多个线程束（Wrap）。</p><p>通过动态调度 Wrap 隐藏内存访问延迟，提升吞吐量。</p><h3 id="线程束-wrap" tabindex="-1"><a class="header-anchor" href="#线程束-wrap"><span>线程束（Wrap）</span></a></h3><p>1个 Wrap 包含32个线程，是 SM 的最小调度单位。所有线程执行相同的指令（SIMT 模式），但操作不同的数据。</p><h3 id="线程块-block-和-wrap-的映射" tabindex="-1"><a class="header-anchor" href="#线程块-block-和-wrap-的映射"><span>线程块（Block）和 Wrap 的映射</span></a></h3><p>Block 被分配到 SM 后，硬件将其划分为多个 Wrap。</p><p>设计建议</p><ul><li>设置 Block 大小为 32 的倍数，避免资源浪费。</li></ul><h3 id="合并访问-coalesced-access" tabindex="-1"><a class="header-anchor" href="#合并访问-coalesced-access"><span>合并访问（Coalesced Access）</span></a></h3><p>确保同一 Wrap 的线程访问全局内存的连续地址，减少内存事务访问。</p><h3 id="共享内存分块" tabindex="-1"><a class="header-anchor" href="#共享内存分块"><span>共享内存分块</span></a></h3><p>将全局内存数据分块加载到共享内存，利用局部性减少重复访问，同时避免 Bank Conflict（如 通过内存填充或对齐）。</p>',29),p=[c];function s(d,h){return r(),a("div",null,p)}const _=e(o,[["render",s],["__file","GPU_CUDA编程.html.vue"]]),m=JSON.parse('{"path":"/other/GPU_CUDA%E7%BC%96%E7%A8%8B.html","title":"GPU，CUDA 编程","lang":"zh-CN","frontmatter":{"title":"GPU，CUDA 编程","category":["GPU"],"description":"GPU，CUDA 编程 以下内容来自个人理解 + 大语言模型 回答 CUDA 版本选择 CUDA 版本选择注意要搭配对应的 NVIDIA 驱动版本： win10 查看GPU型号，驱动版本，CUDA版本_怎么查看gpu版本号-CSDN博客 不同版本cuda对应的NVIDIA驱动版本_cuda12.1对应的驱动版本-CSDN博客 CPU 与 GPU 图片来...","head":[["meta",{"property":"og:url","content":"https://raylan-chen.github.io/other/GPU_CUDA%E7%BC%96%E7%A8%8B.html"}],["meta",{"property":"og:site_name","content":"MyBlog"}],["meta",{"property":"og:title","content":"GPU，CUDA 编程"}],["meta",{"property":"og:description","content":"GPU，CUDA 编程 以下内容来自个人理解 + 大语言模型 回答 CUDA 版本选择 CUDA 版本选择注意要搭配对应的 NVIDIA 驱动版本： win10 查看GPU型号，驱动版本，CUDA版本_怎么查看gpu版本号-CSDN博客 不同版本cuda对应的NVIDIA驱动版本_cuda12.1对应的驱动版本-CSDN博客 CPU 与 GPU 图片来..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-10T13:37:16.000Z"}],["meta",{"property":"article:author","content":"raylan.chen"}],["meta",{"property":"article:modified_time","content":"2025-08-10T13:37:16.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"GPU，CUDA 编程\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2025-08-10T13:37:16.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"raylan.chen\\",\\"url\\":\\"\\"}]}"]]},"headers":[{"level":2,"title":"CUDA 版本选择","slug":"cuda-版本选择","link":"#cuda-版本选择","children":[]},{"level":2,"title":"CPU 与 GPU","slug":"cpu-与-gpu","link":"#cpu-与-gpu","children":[]},{"level":2,"title":"CUDA","slug":"cuda","link":"#cuda","children":[]},{"level":2,"title":"概念理解","slug":"概念理解","link":"#概念理解","children":[{"level":3,"title":"SM（Streaming Multiprocessor）","slug":"sm-streaming-multiprocessor","link":"#sm-streaming-multiprocessor","children":[]},{"level":3,"title":"线程束（Wrap）","slug":"线程束-wrap","link":"#线程束-wrap","children":[]},{"level":3,"title":"线程块（Block）和 Wrap 的映射","slug":"线程块-block-和-wrap-的映射","link":"#线程块-block-和-wrap-的映射","children":[]},{"level":3,"title":"合并访问（Coalesced Access）","slug":"合并访问-coalesced-access","link":"#合并访问-coalesced-access","children":[]},{"level":3,"title":"共享内存分块","slug":"共享内存分块","link":"#共享内存分块","children":[]}]}],"git":{"createdTime":1741755752000,"updatedTime":1754833036000,"contributors":[{"name":"Raylan.Chen","email":"chen.z.my@qq.com","commits":2}]},"readingTime":{"minutes":2.35,"words":704},"filePathRelative":"other/GPU_CUDA编程.md","localizedDate":"2025年3月12日","excerpt":"\\n<blockquote>\\n<p>以下内容来自个人理解 + 大语言模型 回答</p>\\n</blockquote>\\n<h2>CUDA 版本选择</h2>\\n<p>CUDA 版本选择注意要搭配对应的 NVIDIA 驱动版本：</p>\\n<p><a href=\\"https://blog.csdn.net/Strive_For_Future/article/details/104388165\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">win10 查看GPU型号，驱动版本，CUDA版本_怎么查看gpu版本号-CSDN博客</a></p>\\n<p><a href=\\"https://blog.csdn.net/mouse1598189/article/details/86695400\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">不同版本cuda对应的NVIDIA驱动版本_cuda12.1对应的驱动版本-CSDN博客</a></p>","autoDesc":true}');export{_ as comp,m as data};
